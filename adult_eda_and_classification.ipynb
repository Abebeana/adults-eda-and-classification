{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Dataset - Exploratory Data Analysis and Classification\n",
    "\n",
    "This notebook downloads the Adult dataset from the UCI Machine Learning Repository, performs exploratory data analysis, and builds classification models to predict whether income exceeds $50K/year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset from UCI repository\n",
    "print(\"Downloading Adult dataset from UCI repository...\")\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# Get features and target\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "# Combine into single dataframe for EDA\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary of Numerical Features:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(df['income'].value_counts())\n",
    "print(f\"\\nPercentage distribution:\")\n",
    "print(df['income'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Target Variable Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target variable distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['income'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Distribution of Income', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Income', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "if 'income' in numerical_cols:\n",
    "    numerical_cols.remove('income')\n",
    "\n",
    "print(f\"Numerical columns: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols[:6]):\n",
    "    axes[idx].hist(df[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for numerical features by income\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols[:6]):\n",
    "    df.boxplot(column=col, by='income', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{col} by Income')\n",
    "    axes[idx].set_xlabel('Income')\n",
    "    axes[idx].set_ylabel(col)\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'income' in categorical_cols:\n",
    "    categorical_cols.remove('income')\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plots for categorical features\n",
    "n_cols = 3\n",
    "n_rows = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    if idx < len(axes):\n",
    "        df[col].value_counts().plot(kind='bar', ax=axes[idx], color='steelblue')\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Count')\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(categorical_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income distribution by categorical features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "important_cats = ['workclass', 'education', 'marital-status', 'occupation']\n",
    "for idx, col in enumerate(important_cats[:4]):\n",
    "    if col in df.columns:\n",
    "        pd.crosstab(df[col], df['income'], normalize='index').plot(kind='bar', ax=axes[idx], stacked=True)\n",
    "        axes[idx].set_title(f'Income Distribution by {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Proportion')\n",
    "        axes[idx].legend(title='Income')\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Numerical Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Handle missing values (if any) by dropping rows with missing values\n",
    "df_processed = df_processed.dropna()\n",
    "\n",
    "print(f\"Shape after handling missing values: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_processed[col] = le.fit_transform(df_processed[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "df_processed['income'] = le_target.fit_transform(df_processed['income'])\n",
    "\n",
    "print(\"Encoding completed!\")\n",
    "print(f\"Target classes: {le_target.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_processed.drop('income', axis=1)\n",
    "y = df_processed['income']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting model\n",
    "print(\"Training Gradient Boosting model...\")\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "y_pred_proba_gb = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nGradient Boosting Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_gb):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb, target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "models_performance = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_lr),\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_gb)\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        roc_auc_score(y_test, y_pred_proba_lr),\n",
    "        roc_auc_score(y_test, y_pred_proba_rf),\n",
    "        roc_auc_score(y_test, y_pred_proba_gb)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(models_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].bar(models_performance['Model'], models_performance['Accuracy'], color=['skyblue', 'lightgreen', 'salmon'])\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim([0.7, 0.9])\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ROC-AUC comparison\n",
    "axes[1].bar(models_performance['Model'], models_performance['ROC-AUC'], color=['skyblue', 'lightgreen', 'salmon'])\n",
    "axes[1].set_title('Model ROC-AUC Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('ROC-AUC Score')\n",
    "axes[1].set_ylim([0.7, 0.95])\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models_preds = [\n",
    "    ('Logistic Regression', y_pred_lr),\n",
    "    ('Random Forest', y_pred_rf),\n",
    "    ('Gradient Boosting', y_pred_gb)\n",
    "]\n",
    "\n",
    "for idx, (model_name, y_pred) in enumerate(models_preds):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx], \n",
    "                xticklabels=le_target.classes_, yticklabels=le_target.classes_)\n",
    "    axes[idx].set_title(f'{model_name}\\nConfusion Matrix', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "models_proba = [\n",
    "    ('Logistic Regression', y_pred_proba_lr),\n",
    "    ('Random Forest', y_pred_proba_rf),\n",
    "    ('Gradient Boosting', y_pred_proba_gb)\n",
    "]\n",
    "\n",
    "for model_name, y_pred_proba in models_proba:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.4f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=2)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'][:15], feature_importance['importance'][:15], color='steelblue')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Dataset**: The Adult dataset contains demographic and employment information to predict whether an individual earns more than $50K/year.\n",
    "\n",
    "2. **Data Characteristics**: The dataset is imbalanced with more individuals earning <=50K than >50K.\n",
    "\n",
    "3. **Model Performance**: All three models achieved good performance:\n",
    "   - Logistic Regression provides a good baseline\n",
    "   - Random Forest and Gradient Boosting typically achieve higher accuracy\n",
    "   - The best model can be selected based on the specific requirements (accuracy vs interpretability)\n",
    "\n",
    "4. **Important Features**: Features like education, age, capital-gain, and occupation are typically the most important predictors.\n",
    "\n",
    "5. **Next Steps**: \n",
    "   - Hyperparameter tuning for better performance\n",
    "   - Handle class imbalance with techniques like SMOTE\n",
    "   - Try ensemble methods\n",
    "   - Deploy the best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
